{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_243_Select_models_and_parameters-Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "O67uhlT4MExK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "_Lambda School Data Science — Model Validation_\n",
        "\n",
        "# Select models and parameters\n",
        "\n",
        "Objectives\n",
        "- Hyperparameter optimization\n",
        "- Model selection"
      ]
    },
    {
      "metadata": {
        "id": "VE4rfZd4NUGA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Today we'll use this process:\n",
        "\n",
        "## \"A universal workflow of machine learning\"\n",
        "\n",
        "_Excerpt from Francois Chollet, [Deep Learning with Python](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/README.md), Chapter 4: Fundamentals of machine learning_\n",
        " \n",
        "**1. Define the problem at hand and the data on which you’ll train.** Collect this data, or annotate it with labels if need be.\n",
        "\n",
        "**2. Choose how you’ll measure success on your problem.** Which metrics will you monitor on your validation data?\n",
        "\n",
        "**3. Determine your evaluation protocol:** hold-out validation? K-fold validation? Which portion of the data should you use for validation?\n",
        "\n",
        "**4. Develop a first model that does better than a basic baseline:** a model with statistical power.\n",
        "\n",
        "**5. Develop a model that overfits.** The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\n",
        "\n",
        "**6. Regularize your model and tune its hyperparameters, based on performance on the validation data.** Repeatedly modify your model, train it, evaluate on your validation data (not the test data, at this point), modify it again, and repeat, until the model is as good as it can get. \n",
        "\n",
        "Iterate on feature engineering: add new features, or remove features that don’t seem to be informative. Once you’ve developed a satisfactory model configuration, you can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\n"
      ]
    },
    {
      "metadata": {
        "id": "3kt6bzEcOIaa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Define the problem at hand and the data on which you'll train"
      ]
    },
    {
      "metadata": {
        "id": "di16k7vpRg67",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll apply the workflow to a [project from _Python Data Science Handbook_](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic) by Jake VanderPlas:\n",
        "\n",
        "> **Predicting Bicycle Traffic**\n",
        "\n",
        "> As an example, let's take a look at whether we can predict the number of bicycle trips across Seattle's Fremont Bridge based on weather, season, and other factors.\n",
        "\n",
        "> We will join the bike data with another dataset, and try to determine the extent to which weather and seasonal factors—temperature, precipitation, and daylight hours—affect the volume of bicycle traffic through this corridor. Fortunately, the NOAA makes available their daily [weather station data](http://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND) (I used station ID USW00024233) and we can easily use Pandas to join the two data sources.\n",
        "\n",
        "> Let's start by loading the two datasets, indexing by date:"
      ]
    },
    {
      "metadata": {
        "id": "19dpb_d0R1A6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So this is a regression problem, not a classification problem. We'll define the target, choose an evaluation metric, and choose models that are appropriate for regression problems.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "os1zruXQ30KM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download data"
      ]
    },
    {
      "metadata": {
        "id": "5XVu-HSeMDtV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD\n",
        "#!wget https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/master/notebooks/data/BicycleWeather.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9GYm74kD34OQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ]
    },
    {
      "metadata": {
        "id": "BfQ7gE28MNdF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Modified from cells 15, 16, and 20, at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "counts = pd.read_csv('FremontBridge.csv', index_col='Date', parse_dates=True, \n",
        "                     infer_datetime_format=True)\n",
        "\n",
        "weather = pd.read_csv('BicycleWeather.csv', index_col='DATE', parse_dates=True, \n",
        "                      infer_datetime_format=False)\n",
        "\n",
        "daily = counts.resample('d').sum()\n",
        "daily['Total'] = daily.sum(axis=1)\n",
        "daily = daily[['Total']] # remove other columns\n",
        "\n",
        "weather_columns = ['PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND']\n",
        "daily = daily.join(weather[weather_columns], how='inner')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JfbsfviRx7fb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Shifting and duplicating the row to make sure we have yesterday & today's data side by side."
      ]
    },
    {
      "metadata": {
        "id": "i0YYD6rvypb4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make a feature for yesterday's total\n",
        "daily['Total_yesterday'] = daily.Total.shift(1)\n",
        "\n",
        "daily = daily.drop(index=daily.index[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VVB3g4704An5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### First fast look at the data\n",
        "- What's the shape?\n",
        "- What's the date range?\n",
        "- What's the target and the features?"
      ]
    },
    {
      "metadata": {
        "id": "t50E2fTUWBBU",
        "colab_type": "code",
        "outputId": "fb79113b-9e79-475e-b86e-05af9332af82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "daily.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1063, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "eO-R2FoXyLLI",
        "colab_type": "code",
        "outputId": "81bf2e91-2eac-4e48-998b-01b1e35456a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "daily.tail()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>SNOW</th>\n",
              "      <th>SNWD</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>AWND</th>\n",
              "      <th>Total_yesterday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2015-08-28</th>\n",
              "      <td>2653.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>156</td>\n",
              "      <td>26</td>\n",
              "      <td>4336.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-29</th>\n",
              "      <td>699.0</td>\n",
              "      <td>325</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>222</td>\n",
              "      <td>133</td>\n",
              "      <td>58</td>\n",
              "      <td>2653.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-30</th>\n",
              "      <td>1213.0</td>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>200</td>\n",
              "      <td>128</td>\n",
              "      <td>47</td>\n",
              "      <td>699.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-08-31</th>\n",
              "      <td>2823.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>189</td>\n",
              "      <td>161</td>\n",
              "      <td>58</td>\n",
              "      <td>1213.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015-09-01</th>\n",
              "      <td>2876.0</td>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>194</td>\n",
              "      <td>139</td>\n",
              "      <td>-9999</td>\n",
              "      <td>2823.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Total  PRCP  SNOW  SNWD  TMAX  TMIN  AWND  Total_yesterday\n",
              "2015-08-28  2653.0     5     0     0   233   156    26           4336.0\n",
              "2015-08-29   699.0   325     0     0   222   133    58           2653.0\n",
              "2015-08-30  1213.0   102     0     0   200   128    47            699.0\n",
              "2015-08-31  2823.0     0     0     0   189   161    58           1213.0\n",
              "2015-09-01  2876.0    58     0     0   194   139 -9999           2823.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "XgMvCsaWJR7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Target\n",
        "- Total : Daily total number of bicycle trips across Seattle's Fremont Bridge\n",
        "\n",
        "Features\n",
        "- Date (index) : from 2012-10-04 to 2015-09-01\n",
        "- Total_yesterday : Total trips yesterday\n",
        "- PRCP : Precipitation (1/10 mm)\n",
        "- SNOW : Snowfall (1/10 mm)\n",
        "- SNWD : Snow depth (1/10 mm)\n",
        "- TMAX : Maximum temperature (1/10 Celsius)\n",
        "- TMIN : Minimum temperature (1/10 Celsius)\n",
        "- AWND : Average daily wind speed (1/10 meters per second)"
      ]
    },
    {
      "metadata": {
        "id": "lenL-przSYCo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Choose how you’ll measure success on your problem.\n",
        "\n",
        "Which metrics will you monitor on your validation data?\n",
        "\n",
        "This is a regression problem, so we need to choose a regression [metric](https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values).\n",
        "\n",
        "\n",
        "\n",
        "I'll choose Mean Absolute Error.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1TqbomapSyRP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IRHrB3rsS5hF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Determine your evaluation protocol \n",
        "\n",
        "We're doing model selection, hyperparameter optimization, and performance estimation. So generally we have two ideal [options](https://sebastianraschka.com/images/blog/2018/model-evaluation-selection-part4/model-eval-conclusions.jpg) to choose from:\n",
        "\n",
        "- 3-way holdout method (train/validation/test split)\n",
        "- Cross-validation with independent test set\n",
        "\n",
        "I'll choose cross-validation with independent test set. Scikit-learn makes cross-validation convenient for us!\n",
        "\n",
        "Specifically, I will use random shuffled cross validation to train and validate, but I will hold out an \"out-of-time\" test set, from the last 100 days of data:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "A3xo6HgbPMFm",
        "colab_type": "code",
        "outputId": "a3b6b1b8-185a-42bf-eb0c-fc26b7249cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "daily.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1063, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "PfsCH1Oj1DBv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = daily[:-100]\n",
        "test = daily[-100:]\n",
        "\n",
        "# Use test.index to check these"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8TGYRDI21RVX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = train.drop(columns='Total')\n",
        "y_train = train.Total\n",
        "\n",
        "X_test = test.drop(columns='Total')\n",
        "y_test = test.Total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vH6IsORQTvTU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Develop a first model that does better than a basic baseline"
      ]
    },
    {
      "metadata": {
        "id": "DJBs2nQkj7oB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Look at the target's distribution and descriptive stats"
      ]
    },
    {
      "metadata": {
        "id": "P5peakv9Zs71",
        "colab_type": "code",
        "outputId": "0ba18f82-18b2-47fd-eeb9-3cd0bca94f81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(y_train);"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py:6521: MatplotlibDeprecationWarning: \n",
            "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
            "  alternative=\"'density'\", removal=\"3.1\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFYCAYAAACoFn5YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxMb+f/+WYf7QW193AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "fEjxxgV9kExY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic baseline 1"
      ]
    },
    {
      "metadata": {
        "id": "6GepKdQjYcEP",
        "colab_type": "code",
        "outputId": "66dd7e92-40da-4f43-dca9-aca2fb1b5c02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred = np.full(shape=y_train.shape, fill_value=y_train.mean())# TODO\n",
        "baseline = mean_absolute_error(y_train, y_pred)\n",
        "baseline1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "980.8981106765484"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "tN2I_F3FkIHb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic baseline 2"
      ]
    },
    {
      "metadata": {
        "id": "gzikv0OM3Edd",
        "colab_type": "code",
        "outputId": "97f6f782-1fe6-4609-d4d3-8631618cc687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "mean_absolute_error(y_train, X_train.Total_yesterday)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "708.061266874351"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "Ggf3VpxwkJ0T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### First model that does better than a basic baseline (Using `Cross Validation`)\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KfaqL1Ezer2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html"
      ]
    },
    {
      "metadata": {
        "id": "ZW8bhZFtTunV",
        "colab_type": "code",
        "outputId": "ef9bf23d-bfb5-4b36-b30c-2d7ebb43379e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LinearRegression \n",
        "\n",
        "# CV returns a dictionary so.... \n",
        "scores = cross_validate(LinearRegression(), X_train, y_train, scoring='neg_mean_absolute_error', cv = 3, return_train_score=True, return_estimator=True)\n",
        "\n",
        "# You can just drop it into a pandas dataframe and BOOM: pretty print! \n",
        "pd.DataFrame(scores).rename(columns={\"test_score\": 'validation_score'})\n",
        "# The test score is actually the scores from each validation cycle."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>validation_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.002355</td>\n",
              "      <td>0.002893</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-619.509206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.002064</td>\n",
              "      <td>0.001476</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-583.427702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.001823</td>\n",
              "      <td>0.001524</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-589.341301</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           estimator  fit_time  score_time  \\\n",
              "0  LinearRegression(copy_X=True, fit_intercept=Tr...  0.002355    0.002893   \n",
              "1  LinearRegression(copy_X=True, fit_intercept=Tr...  0.002064    0.001476   \n",
              "2  LinearRegression(copy_X=True, fit_intercept=Tr...  0.001823    0.001524   \n",
              "\n",
              "   validation_score  train_score  \n",
              "0       -555.186275  -619.509206  \n",
              "1       -651.126513  -583.427702  \n",
              "2       -615.965800  -589.341301  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "cijaQUrB68Py",
        "colab_type": "code",
        "outputId": "3557055b-432c-4867-bf0a-4d9bf36cf667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        }
      },
      "cell_type": "code",
      "source": [
        "scores['test_score'].mean()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-607.4261958631806"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "i_G9ZDb45KWS",
        "colab_type": "code",
        "outputId": "488d28c9-5879-4559-c9d6-ecabb69be3ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "cell_type": "code",
      "source": [
        "for i, model in enumerate(scores['estimator']): \n",
        "  coeffs = model.coef_\n",
        "  intercpt = model.intercept_\n",
        "  feature_names = X_train.columns\n",
        "  \n",
        "  print('Model from cross validation fold #' + str (i))\n",
        "  print('intercpt', model.intercept_)\n",
        "  print(pd.Series(coeffs, feature_names).to_string())\n",
        "  print('\\n')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model from cross validation fold #0\n",
            "intercpt 566.7766337283679\n",
            "PRCP               -3.525103\n",
            "SNOW               -0.082029\n",
            "SNWD              -12.045027\n",
            "TMAX                9.475238\n",
            "TMIN               -4.607775\n",
            "AWND               -2.745191\n",
            "Total_yesterday     0.417360\n",
            "\n",
            "\n",
            "Model from cross validation fold #1\n",
            "intercpt 671.9064515706045\n",
            "PRCP               -2.772253\n",
            "SNOW               -0.000995\n",
            "SNWD               20.800688\n",
            "TMAX                8.804948\n",
            "TMIN               -3.741386\n",
            "AWND               -6.108300\n",
            "Total_yesterday     0.405074\n",
            "\n",
            "\n",
            "Model from cross validation fold #2\n",
            "intercpt 465.84525362296563\n",
            "PRCP               -2.876196\n",
            "SNOW               -0.016432\n",
            "SNWD               -8.809696\n",
            "TMAX               10.419441\n",
            "TMIN               -5.862868\n",
            "AWND               -2.398991\n",
            "Total_yesterday     0.423493\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZeYpN7BP6S-i",
        "colab_type": "code",
        "outputId": "efbc3170-23e2-400f-d48c-16f57c76e688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        }
      },
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "model = sm.OLS(y_train, sm.add_constant(X_train)) # add the constant for the x term in statsmodels\n",
        "print(model.fit().summary())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Total   R-squared:                       0.628\n",
            "Model:                            OLS   Adj. R-squared:                  0.625\n",
            "Method:                 Least Squares   F-statistic:                     230.2\n",
            "Date:                Wed, 30 Jan 2019   Prob (F-statistic):          4.80e-200\n",
            "Time:                        21:37:17   Log-Likelihood:                -7736.8\n",
            "No. Observations:                 963   AIC:                         1.549e+04\n",
            "Df Residuals:                     955   BIC:                         1.553e+04\n",
            "Df Model:                           7                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "===================================================================================\n",
            "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------\n",
            "const             571.7691     93.165      6.137      0.000     388.937     754.601\n",
            "PRCP               -3.0616      0.396     -7.726      0.000      -3.839      -2.284\n",
            "SNOW               -0.0271      0.038     -0.721      0.471      -0.101       0.047\n",
            "SNWD               -9.1379      8.974     -1.018      0.309     -26.748       8.472\n",
            "TMAX                9.4823      0.774     12.258      0.000       7.964      11.000\n",
            "TMIN               -4.6742      1.026     -4.555      0.000      -6.688      -2.660\n",
            "AWND               -3.7006      1.747     -2.119      0.034      -7.128      -0.273\n",
            "Total_yesterday     0.4165      0.025     16.460      0.000       0.367       0.466\n",
            "==============================================================================\n",
            "Omnibus:                        6.601   Durbin-Watson:                   1.571\n",
            "Prob(Omnibus):                  0.037   Jarque-Bera (JB):                6.648\n",
            "Skew:                          -0.187   Prob(JB):                       0.0360\n",
            "Kurtosis:                       2.841   Cond. No.                     1.09e+04\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.09e+04. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
            "  from pandas.core import datetools\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Ow1evrV-aSo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Second Model that performs better."
      ]
    },
    {
      "metadata": {
        "id": "mLe8dBa07gCb",
        "colab_type": "code",
        "outputId": "fa06b493-224c-41b7-a24c-30eea09bfd11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# A more ROBUST Regression model???? \n",
        "# I'm going to try a RANSAC regressor to help ignore any bad data values. \n",
        "# RANdom SAmple Consensus (RANSAC) - fits a regresssion models to the inliers of the data. \n",
        "# Inlires \n",
        "from sklearn.linear_model import RANSACRegressor\n",
        "\n",
        "# CV returns a dictionary so.... \n",
        "scores2 = cross_validate(RANSACRegressor(LinearRegression(), max_trials=100, min_samples = 50, loss='absolute_loss'), X_train, y_train, scoring='neg_mean_absolute_error', cv = 3, return_train_score=True, return_estimator=True)\n",
        "\n",
        "# You can just drop it into a pandas dataframe and BOOM: pretty print! \n",
        "pd.DataFrame(scores2).rename(columns={\"test_score\": 'validation_score'})\n",
        "# The test score is actually the scores from each validation cycle."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>validation_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RANSACRegressor(base_estimator=LinearRegressio...</td>\n",
              "      <td>0.073004</td>\n",
              "      <td>0.001951</td>\n",
              "      <td>-586.707318</td>\n",
              "      <td>-624.521454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RANSACRegressor(base_estimator=LinearRegressio...</td>\n",
              "      <td>0.062767</td>\n",
              "      <td>0.002074</td>\n",
              "      <td>-652.577635</td>\n",
              "      <td>-584.777564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RANSACRegressor(base_estimator=LinearRegressio...</td>\n",
              "      <td>0.061582</td>\n",
              "      <td>0.001843</td>\n",
              "      <td>-610.599095</td>\n",
              "      <td>-588.633722</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           estimator  fit_time  score_time  \\\n",
              "0  RANSACRegressor(base_estimator=LinearRegressio...  0.073004    0.001951   \n",
              "1  RANSACRegressor(base_estimator=LinearRegressio...  0.062767    0.002074   \n",
              "2  RANSACRegressor(base_estimator=LinearRegressio...  0.061582    0.001843   \n",
              "\n",
              "   validation_score  train_score  \n",
              "0       -586.707318  -624.521454  \n",
              "1       -652.577635  -584.777564  \n",
              "2       -610.599095  -588.633722  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "fg1YI4X8n9nI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Develop a model that overfits. \n",
        "\n",
        "\"The universal tension in machine learning is between optimization and generalization; the ideal model is one that stands right at the border between underfitting and overfitting; between undercapacity and overcapacity. To figure out where this border lies, first you must cross it.\" —Chollet"
      ]
    },
    {
      "metadata": {
        "id": "lodd6UPOoy89",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/05.03-validation-curve.png\">\n",
        "\n",
        "Diagram source: https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn"
      ]
    },
    {
      "metadata": {
        "id": "FrmQ3RM0w2JE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Polynomial Regression?"
      ]
    },
    {
      "metadata": {
        "id": "uctwo0X3pTw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copied from cell 10 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def PolynomialRegression(degree=2, **kwargs):\n",
        "    return make_pipeline(PolynomialFeatures(degree),\n",
        "                         LinearRegression(**kwargs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wvY4HOXVw7Mj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "4df5355f-7285-476a-9a99-38660ab578fb"
      },
      "cell_type": "code",
      "source": [
        "# See how many features each model\n",
        "for degree in [0, 1, 2, 3]:\n",
        "    features = PolynomialFeatures(degree).fit(X_train).get_feature_names(X_train.columns)\n",
        "    print(f'{degree} degree polynomial has {len(features)} features')\n",
        "    print(features, '\\n')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 degree polynomial has 1 features\n",
            "['1'] \n",
            "\n",
            "1 degree polynomial has 8 features\n",
            "['1', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND', 'Total_yesterday'] \n",
            "\n",
            "2 degree polynomial has 36 features\n",
            "['1', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND', 'Total_yesterday', 'PRCP^2', 'PRCP SNOW', 'PRCP SNWD', 'PRCP TMAX', 'PRCP TMIN', 'PRCP AWND', 'PRCP Total_yesterday', 'SNOW^2', 'SNOW SNWD', 'SNOW TMAX', 'SNOW TMIN', 'SNOW AWND', 'SNOW Total_yesterday', 'SNWD^2', 'SNWD TMAX', 'SNWD TMIN', 'SNWD AWND', 'SNWD Total_yesterday', 'TMAX^2', 'TMAX TMIN', 'TMAX AWND', 'TMAX Total_yesterday', 'TMIN^2', 'TMIN AWND', 'TMIN Total_yesterday', 'AWND^2', 'AWND Total_yesterday', 'Total_yesterday^2'] \n",
            "\n",
            "3 degree polynomial has 120 features\n",
            "['1', 'PRCP', 'SNOW', 'SNWD', 'TMAX', 'TMIN', 'AWND', 'Total_yesterday', 'PRCP^2', 'PRCP SNOW', 'PRCP SNWD', 'PRCP TMAX', 'PRCP TMIN', 'PRCP AWND', 'PRCP Total_yesterday', 'SNOW^2', 'SNOW SNWD', 'SNOW TMAX', 'SNOW TMIN', 'SNOW AWND', 'SNOW Total_yesterday', 'SNWD^2', 'SNWD TMAX', 'SNWD TMIN', 'SNWD AWND', 'SNWD Total_yesterday', 'TMAX^2', 'TMAX TMIN', 'TMAX AWND', 'TMAX Total_yesterday', 'TMIN^2', 'TMIN AWND', 'TMIN Total_yesterday', 'AWND^2', 'AWND Total_yesterday', 'Total_yesterday^2', 'PRCP^3', 'PRCP^2 SNOW', 'PRCP^2 SNWD', 'PRCP^2 TMAX', 'PRCP^2 TMIN', 'PRCP^2 AWND', 'PRCP^2 Total_yesterday', 'PRCP SNOW^2', 'PRCP SNOW SNWD', 'PRCP SNOW TMAX', 'PRCP SNOW TMIN', 'PRCP SNOW AWND', 'PRCP SNOW Total_yesterday', 'PRCP SNWD^2', 'PRCP SNWD TMAX', 'PRCP SNWD TMIN', 'PRCP SNWD AWND', 'PRCP SNWD Total_yesterday', 'PRCP TMAX^2', 'PRCP TMAX TMIN', 'PRCP TMAX AWND', 'PRCP TMAX Total_yesterday', 'PRCP TMIN^2', 'PRCP TMIN AWND', 'PRCP TMIN Total_yesterday', 'PRCP AWND^2', 'PRCP AWND Total_yesterday', 'PRCP Total_yesterday^2', 'SNOW^3', 'SNOW^2 SNWD', 'SNOW^2 TMAX', 'SNOW^2 TMIN', 'SNOW^2 AWND', 'SNOW^2 Total_yesterday', 'SNOW SNWD^2', 'SNOW SNWD TMAX', 'SNOW SNWD TMIN', 'SNOW SNWD AWND', 'SNOW SNWD Total_yesterday', 'SNOW TMAX^2', 'SNOW TMAX TMIN', 'SNOW TMAX AWND', 'SNOW TMAX Total_yesterday', 'SNOW TMIN^2', 'SNOW TMIN AWND', 'SNOW TMIN Total_yesterday', 'SNOW AWND^2', 'SNOW AWND Total_yesterday', 'SNOW Total_yesterday^2', 'SNWD^3', 'SNWD^2 TMAX', 'SNWD^2 TMIN', 'SNWD^2 AWND', 'SNWD^2 Total_yesterday', 'SNWD TMAX^2', 'SNWD TMAX TMIN', 'SNWD TMAX AWND', 'SNWD TMAX Total_yesterday', 'SNWD TMIN^2', 'SNWD TMIN AWND', 'SNWD TMIN Total_yesterday', 'SNWD AWND^2', 'SNWD AWND Total_yesterday', 'SNWD Total_yesterday^2', 'TMAX^3', 'TMAX^2 TMIN', 'TMAX^2 AWND', 'TMAX^2 Total_yesterday', 'TMAX TMIN^2', 'TMAX TMIN AWND', 'TMAX TMIN Total_yesterday', 'TMAX AWND^2', 'TMAX AWND Total_yesterday', 'TMAX Total_yesterday^2', 'TMIN^3', 'TMIN^2 AWND', 'TMIN^2 Total_yesterday', 'TMIN AWND^2', 'TMIN AWND Total_yesterday', 'TMIN Total_yesterday^2', 'AWND^3', 'AWND^2 Total_yesterday', 'AWND Total_yesterday^2', 'Total_yesterday^3'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PYmg5gnSAOc4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Polynomial regression can create additional multicolinearatity, but we only care about fit. \n",
        "So if it fails to converge then it may be an issue.\n",
        "But if it does converge and it is better then it's not an issue. "
      ]
    },
    {
      "metadata": {
        "id": "XEUdG9-ktHoa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation curve (with Polynomial Regression)"
      ]
    },
    {
      "metadata": {
        "id": "_ryO1hVKr-6f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.validation_curve.html\n",
        "\n",
        "> Validation curve. Determine training and test scores for varying parameter values. This is similar to grid search with one parameter."
      ]
    },
    {
      "metadata": {
        "id": "znJgKqPcqBh-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "bcb3df62-0623-4afd-f186-b0a23261b939"
      },
      "cell_type": "code",
      "source": [
        "# Modified from cell 13 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "degree = [0, 1, 2]\n",
        "train_score, val_score = validation_curve(\n",
        "    PolynomialRegression(), X_train, y_train,\n",
        "    param_name='polynomialfeatures__degree', param_range=degree, \n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "\n",
        "plt.plot(degree, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(degree, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('degree');"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfGBkzSy2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "HUdGHWhvtVnV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Grid Search (with Polynomial Regression)\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/grid_search.html\n",
        "\n",
        "You need to keep this process light weight.\n",
        "\n",
        "\n",
        "*Note: If your model takes an exhaustive amount of time you need to:*\n",
        "* Take a smaller sample size.\n",
        "* Keep running gridsearch running fast. \n",
        "* Use CV random\n"
      ]
    },
    {
      "metadata": {
        "id": "GziXyq8Is6dL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "70ca1023-f5c5-4210-ae9b-2c8a1e735583"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'polynomialfeatures__degree': [0,1,2,3]\n",
        "}\n",
        "\n",
        "gridsearch = GridSearchCV(PolynomialRegression(), param_grid=param_grid, scoring='neg_mean_absolute_error', cv=3, return_train_score=True, verbose=10)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
            "[CV] polynomialfeatures__degree=0 ....................................\n",
            "[CV]  polynomialfeatures__degree=0, score=-1026.3529857047195, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=0 ....................................\n",
            "[CV]  polynomialfeatures__degree=0, score=-1001.6149251268913, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=0 ....................................\n",
            "[CV]  polynomialfeatures__degree=0, score=-927.0707048650538, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=1 ....................................\n",
            "[CV]  polynomialfeatures__degree=1, score=-555.1862745374103, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=1 ....................................\n",
            "[CV]  polynomialfeatures__degree=1, score=-651.1265132746228, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=1 ....................................\n",
            "[CV]  polynomialfeatures__degree=1, score=-615.9657997775082, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=2 ....................................\n",
            "[CV]  polynomialfeatures__degree=2, score=-7553.67367810515, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=2 ....................................\n",
            "[CV]  polynomialfeatures__degree=2, score=-1439.191570208428, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=2 ....................................\n",
            "[CV]  polynomialfeatures__degree=2, score=-644.1228337571547, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=3 ....................................\n",
            "[CV]  polynomialfeatures__degree=3, score=-2487.2087241103723, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=3 ....................................\n",
            "[CV]  polynomialfeatures__degree=3, score=-97950.22398935535, total=   0.0s\n",
            "[CV] polynomialfeatures__degree=3 ....................................\n",
            "[CV]  polynomialfeatures__degree=3, score=-1835.2490429251202, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "       estimator=Pipeline(memory=None,\n",
              "     steps=[('polynomialfeatures', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
              "         normalize=False))]),\n",
              "       fit_params=None, iid='warn', n_jobs=None,\n",
              "       param_grid={'polynomialfeatures__degree': [0, 1, 2, 3]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
              "       scoring='neg_mean_absolute_error', verbose=10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "z9-72w6XCu90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "f8b2ebbc-f2cb-4b09-9017-4058c6a777b8"
      },
      "cell_type": "code",
      "source": [
        "# Here you can see \n",
        "pd.DataFrame(gridsearch.cv_results_).sort_values(by='rank_test_score')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>mean_train_score</th>\n",
              "      <th>param_polynomialfeatures__degree</th>\n",
              "      <th>params</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split0_train_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split1_train_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split2_train_score</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>std_train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003019</td>\n",
              "      <td>0.001877</td>\n",
              "      <td>-607.426196</td>\n",
              "      <td>-597.426070</td>\n",
              "      <td>1</td>\n",
              "      <td>{'polynomialfeatures__degree': 1}</td>\n",
              "      <td>1</td>\n",
              "      <td>-555.186275</td>\n",
              "      <td>-619.509206</td>\n",
              "      <td>-651.126513</td>\n",
              "      <td>-583.427702</td>\n",
              "      <td>-615.965800</td>\n",
              "      <td>-589.341301</td>\n",
              "      <td>0.000181</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>39.630174</td>\n",
              "      <td>15.800661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.003385</td>\n",
              "      <td>0.001850</td>\n",
              "      <td>-985.012872</td>\n",
              "      <td>-979.844161</td>\n",
              "      <td>0</td>\n",
              "      <td>{'polynomialfeatures__degree': 0}</td>\n",
              "      <td>2</td>\n",
              "      <td>-1026.352986</td>\n",
              "      <td>-968.880368</td>\n",
              "      <td>-1001.614925</td>\n",
              "      <td>-970.755413</td>\n",
              "      <td>-927.070705</td>\n",
              "      <td>-999.896701</td>\n",
              "      <td>0.000528</td>\n",
              "      <td>0.000330</td>\n",
              "      <td>42.197661</td>\n",
              "      <td>14.199935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.005354</td>\n",
              "      <td>0.004240</td>\n",
              "      <td>-3212.329361</td>\n",
              "      <td>-576.333816</td>\n",
              "      <td>2</td>\n",
              "      <td>{'polynomialfeatures__degree': 2}</td>\n",
              "      <td>3</td>\n",
              "      <td>-7553.673678</td>\n",
              "      <td>-595.089615</td>\n",
              "      <td>-1439.191570</td>\n",
              "      <td>-568.150803</td>\n",
              "      <td>-644.122834</td>\n",
              "      <td>-565.761032</td>\n",
              "      <td>0.000459</td>\n",
              "      <td>0.002079</td>\n",
              "      <td>3086.906373</td>\n",
              "      <td>13.298189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.015335</td>\n",
              "      <td>0.004445</td>\n",
              "      <td>-34090.893919</td>\n",
              "      <td>-601.797899</td>\n",
              "      <td>3</td>\n",
              "      <td>{'polynomialfeatures__degree': 3}</td>\n",
              "      <td>4</td>\n",
              "      <td>-2487.208724</td>\n",
              "      <td>-565.787908</td>\n",
              "      <td>-97950.223989</td>\n",
              "      <td>-663.520180</td>\n",
              "      <td>-1835.249043</td>\n",
              "      <td>-576.085609</td>\n",
              "      <td>0.001038</td>\n",
              "      <td>0.000118</td>\n",
              "      <td>45156.149752</td>\n",
              "      <td>43.846251</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
              "1       0.003019         0.001877      -607.426196       -597.426070   \n",
              "0       0.003385         0.001850      -985.012872       -979.844161   \n",
              "2       0.005354         0.004240     -3212.329361       -576.333816   \n",
              "3       0.015335         0.004445    -34090.893919       -601.797899   \n",
              "\n",
              "  param_polynomialfeatures__degree                             params  \\\n",
              "1                                1  {'polynomialfeatures__degree': 1}   \n",
              "0                                0  {'polynomialfeatures__degree': 0}   \n",
              "2                                2  {'polynomialfeatures__degree': 2}   \n",
              "3                                3  {'polynomialfeatures__degree': 3}   \n",
              "\n",
              "   rank_test_score  split0_test_score  split0_train_score  split1_test_score  \\\n",
              "1                1        -555.186275         -619.509206        -651.126513   \n",
              "0                2       -1026.352986         -968.880368       -1001.614925   \n",
              "2                3       -7553.673678         -595.089615       -1439.191570   \n",
              "3                4       -2487.208724         -565.787908      -97950.223989   \n",
              "\n",
              "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
              "1         -583.427702        -615.965800         -589.341301      0.000181   \n",
              "0         -970.755413        -927.070705         -999.896701      0.000528   \n",
              "2         -568.150803        -644.122834         -565.761032      0.000459   \n",
              "3         -663.520180       -1835.249043         -576.085609      0.001038   \n",
              "\n",
              "   std_score_time  std_test_score  std_train_score  \n",
              "1        0.000093       39.630174        15.800661  \n",
              "0        0.000330       42.197661        14.199935  \n",
              "2        0.002079     3086.906373        13.298189  \n",
              "3        0.000118    45156.149752        43.846251  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "xj82P0VdwYlh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest?\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
      ]
    },
    {
      "metadata": {
        "id": "_yYXpk99C4cM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bee882d1-3c1f-4c65-8b71-2de4f158d20e"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100, max_depth=20)\n",
        "\n",
        "scores = cross_validate(model,X_train, y_train, scoring = 'neg_mean_absolute_error', cv=3, return_train_score=True, return_estimator=True)\n",
        "\n",
        "pd.DataFrame(scores)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>0.213065</td>\n",
              "      <td>0.010788</td>\n",
              "      <td>-563.911130</td>\n",
              "      <td>-242.024939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>0.216826</td>\n",
              "      <td>0.011075</td>\n",
              "      <td>-638.909919</td>\n",
              "      <td>-220.245763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(DecisionTreeRegressor(criterion='mse', max_de...</td>\n",
              "      <td>0.206657</td>\n",
              "      <td>0.010753</td>\n",
              "      <td>-638.747970</td>\n",
              "      <td>-221.205299</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           estimator  fit_time  score_time  \\\n",
              "0  (DecisionTreeRegressor(criterion='mse', max_de...  0.213065    0.010788   \n",
              "1  (DecisionTreeRegressor(criterion='mse', max_de...  0.216826    0.011075   \n",
              "2  (DecisionTreeRegressor(criterion='mse', max_de...  0.206657    0.010753   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -563.911130  -242.024939  \n",
              "1 -638.909919  -220.245763  \n",
              "2 -638.747970  -221.205299  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "vofwgIpSweEb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation Curve (with Random Forest)"
      ]
    },
    {
      "metadata": {
        "id": "apKk4vKiwgtM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "d0753e58-5d60-4a4c-d90a-6d3281221713"
      },
      "cell_type": "code",
      "source": [
        "# Modified from cell 13 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import validation_curve\n",
        "\n",
        "model = RandomForestRegressor(n_estimators=100)\n",
        "\n",
        "depth = [2, 3, 4, 5, 6]\n",
        "train_score, val_score = validation_curve(\n",
        "    model, X_train, y_train,\n",
        "    param_name='max_depth', param_range=depth, \n",
        "    scoring='neg_mean_absolute_error', cv=3)\n",
        "\n",
        "plt.plot(depth, np.median(train_score, 1), color='blue', label='training score')\n",
        "plt.plot(depth, np.median(val_score, 1), color='red', label='validation score')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('depth');"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nz7tOKu9NfCoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "DQoMvZ7-yCAQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Grid Search (with Random Forest)"
      ]
    },
    {
      "metadata": {
        "id": "iQJcFhaoE8Gx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "3b0f019a-2379-4790-a387-01c2aa497b71"
      },
      "cell_type": "code",
      "source": [
        "# this is my grid search\n",
        "# think columns x rows \n",
        "%%time\n",
        "param_grid = {\n",
        "    'n_estimators:': [100, 200],\n",
        "    'max_depth': [4, 5, 6, 7],\n",
        "    'criterion': ['mse', 'mae']\n",
        "}\n",
        "# paramgrid is my dictionary of things to change.\n",
        "gridsearch = GridSearchCV(RandomForestRegressor(), param_grid=param_grid, scoring='neg_mean_absolute_error', cv=3, return_train_score=True, verbose=2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 86 µs, sys: 7 µs, total: 93 µs\n",
            "Wall time: 98.9 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZW5HfYtU0GW2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## FEATURE ENGINEERING! (Beastmode)"
      ]
    },
    {
      "metadata": {
        "id": "0ms-eoOHFvPG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Jake VanderPlas demonstrates this feature engineering: \n",
        "https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic"
      ]
    },
    {
      "metadata": {
        "id": "sEwME8wR3A5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Modified from code cells 17-21 at\n",
        "# https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic\n",
        "\n",
        "\n",
        "# patterns of use generally vary from day to day; \n",
        "# let's add binary columns that indicate the day of the week:\n",
        "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "for i, day in enumerate(days):\n",
        "    X_train[day] = (X_train.index.dayofweek == i).astype(float)\n",
        "\n",
        "\n",
        "    \n",
        "# we might expect riders to behave differently on holidays; \n",
        "# let's add an indicator of this as well:\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "cal = USFederalHolidayCalendar()\n",
        "holidays = cal.holidays('2012', '2016')\n",
        "X_train = X_train.join(pd.Series(1, index=holidays, name='holiday'))\n",
        "X_train['holiday'].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "# We also might suspect that the hours of daylight would affect \n",
        "# how many people ride; let's use the standard astronomical calculation \n",
        "# to add this information:\n",
        "def hours_of_daylight(date, axis=23.44, latitude=47.61):\n",
        "    \"\"\"Compute the hours of daylight for the given date\"\"\"\n",
        "    days = (date - pd.datetime(2000, 12, 21)).days\n",
        "    m = (1. - np.tan(np.radians(latitude))\n",
        "         * np.tan(np.radians(axis) * np.cos(days * 2 * np.pi / 365.25)))\n",
        "    return 24. * np.degrees(np.arccos(1 - np.clip(m, 0, 2))) / 180.\n",
        "\n",
        "X_train['daylight_hrs'] = list(map(hours_of_daylight, X_train.index))\n",
        "\n",
        "\n",
        "\n",
        "# temperatures are in 1/10 deg C; convert to C\n",
        "X_train['TMIN'] /= 10\n",
        "X_train['TMAX'] /= 10\n",
        "\n",
        "# We can also calcuate the average temperature.\n",
        "X_train['Temp (C)'] = 0.5 * (X_train['TMIN'] + X_train['TMAX'])\n",
        "\n",
        "\n",
        "# precip is in 1/10 mm; convert to inches\n",
        "X_train['PRCP'] /= 254\n",
        "\n",
        "# In addition to the inches of precipitation, let's add a flag that \n",
        "# indicates whether a day is dry (has zero precipitation):\n",
        "X_train['dry day'] = (X_train['PRCP'] == 0).astype(int)\n",
        "\n",
        "\n",
        "# Let's add a counter that increases from day 1, and measures how many \n",
        "# years have passed. This will let us measure any observed annual increase \n",
        "# or decrease in daily crossings:\n",
        "X_train['annual'] = (X_train.index - X_train.index[0]).days / 365."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dDGkAv813Wtj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Linear Regression (with new features)"
      ]
    },
    {
      "metadata": {
        "id": "cj3HTM6p5F1A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "eed45336-1eff-40a6-a82f-926358a60c91"
      },
      "cell_type": "code",
      "source": [
        "scores = cross_validate(LinearRegression(),X_train, y_train, scoring = 'neg_mean_absolute_error', cv=3, return_train_score=True, return_estimator=True)\n",
        "pd.DataFrame(scores)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>score_time</th>\n",
              "      <th>test_score</th>\n",
              "      <th>train_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.009240</td>\n",
              "      <td>0.002539</td>\n",
              "      <td>-297.692524</td>\n",
              "      <td>-294.532315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.003241</td>\n",
              "      <td>0.002141</td>\n",
              "      <td>-300.419037</td>\n",
              "      <td>-283.779461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LinearRegression(copy_X=True, fit_intercept=Tr...</td>\n",
              "      <td>0.003054</td>\n",
              "      <td>0.001998</td>\n",
              "      <td>-322.640378</td>\n",
              "      <td>-283.509114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           estimator  fit_time  score_time  \\\n",
              "0  LinearRegression(copy_X=True, fit_intercept=Tr...  0.009240    0.002539   \n",
              "1  LinearRegression(copy_X=True, fit_intercept=Tr...  0.003241    0.002141   \n",
              "2  LinearRegression(copy_X=True, fit_intercept=Tr...  0.003054    0.001998   \n",
              "\n",
              "   test_score  train_score  \n",
              "0 -297.692524  -294.532315  \n",
              "1 -300.419037  -283.779461  \n",
              "2 -322.640378  -283.509114  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "b6zxN2xB3bX_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forest (with new features)"
      ]
    },
    {
      "metadata": {
        "id": "3sWUDZIz1-kk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "2101d5a5-5696-4fd7-d49f-7fbfcc9f2322"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "param_grid = {\n",
        "    'n_estimators:': [100, 200],\n",
        "    'max_depth': [4, 5, 6, 7],\n",
        "    'criterion': ['mse', 'mae']\n",
        "}\n",
        "# paramgrid is my dictionary of things to change.\n",
        "gridsearch = GridSearchCV(RandomForestRegressor(), param_grid=param_grid, scoring='neg_mean_absolute_error', cv=3, return_train_score=True, verbose=2)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 174 µs, sys: 14 µs, total: 188 µs\n",
            "Wall time: 99.4 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0QEBUVR13kcb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Ridge Regression (with new features)\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
      ]
    },
    {
      "metadata": {
        "id": "4voLbIxU8r6r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "bba8f093-4278-4bff-b3f8-3f328717132b"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 1.0, 10.0]\n",
        "}\n",
        "\n",
        "gridsearch = GridSearchCV(Ridge(), param_grid=param_grid, scoring='neg_mean_absolute_error', cv=3, return_train_score=True, verbose=2)\n",
        "\n",
        "gridsearch.fit(X_train, y_train)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................................ alpha=0.1, total=   0.0s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................................ alpha=0.1, total=   0.0s\n",
            "[CV] alpha=0.1 .......................................................\n",
            "[CV] ........................................ alpha=0.1, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................................ alpha=1.0, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................................ alpha=1.0, total=   0.0s\n",
            "[CV] alpha=1.0 .......................................................\n",
            "[CV] ........................................ alpha=1.0, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] ....................................... alpha=10.0, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] ....................................... alpha=10.0, total=   0.0s\n",
            "[CV] alpha=10.0 ......................................................\n",
            "[CV] ....................................... alpha=10.0, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
              "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
              "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
              "       fit_params=None, iid='warn', n_jobs=None,\n",
              "       param_grid={'alpha': [0.1, 1.0, 10.0]}, pre_dispatch='2*n_jobs',\n",
              "       refit=True, return_train_score=True,\n",
              "       scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "E4MQalDoJfXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "581e14ed-6078-4fcf-9c28-5101a4ec83c9"
      },
      "cell_type": "code",
      "source": [
        "# Get the best estimator from the group. \n",
        "model = gridsearch.best_estimator_\n",
        "\n",
        "type(model)\n",
        "\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "feature_names = X_train.columns\n",
        "\n",
        "print(intercept)\n",
        "print(pd.Series(coefficients, feature_names).to_string())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33.741779570641484\n",
            "PRCP               -553.070741\n",
            "SNOW                 -0.002829\n",
            "SNWD                 -1.877519\n",
            "TMAX                 63.833062\n",
            "TMIN                -37.450291\n",
            "AWND                 -1.900084\n",
            "Total_yesterday       0.296029\n",
            "Mon                 779.221395\n",
            "Tue                 432.700039\n",
            "Wed                 368.367626\n",
            "Thu                 274.054021\n",
            "Fri                  47.251356\n",
            "Sat               -1099.692199\n",
            "Sun                -801.902237\n",
            "holiday            -939.301546\n",
            "daylight_hrs         70.256463\n",
            "Temp (C)             13.191386\n",
            "dry day             298.475434\n",
            "annual               44.518889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V02gkEGKJe7X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "dofdwyTf3pm0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compare to statsmodels"
      ]
    },
    {
      "metadata": {
        "id": "i-Qt4mDk_yBY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757
        },
        "outputId": "c167b376-a7d1-4aea-c589-a31b80ce6caa"
      },
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "model = sm.OLS(y_train, sm.add_constant(X_train)) # add the constant for the x term in statsmodels\n",
        "print(model.fit().summary())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  Total   R-squared:                       0.902\n",
            "Model:                            OLS   Adj. R-squared:                  0.901\n",
            "Method:                 Least Squares   F-statistic:                     513.8\n",
            "Date:                Wed, 30 Jan 2019   Prob (F-statistic):               0.00\n",
            "Time:                        21:37:22   Log-Likelihood:                -7092.6\n",
            "No. Observations:                 963   AIC:                         1.422e+04\n",
            "Df Residuals:                     945   BIC:                         1.431e+04\n",
            "Df Model:                          17                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "===================================================================================\n",
            "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------\n",
            "const              33.0481     66.293      0.499      0.618     -97.051     163.147\n",
            "PRCP             -562.6226     56.568     -9.946      0.000    -673.636    -451.609\n",
            "SNOW               -0.0025      0.020     -0.129      0.897      -0.041       0.036\n",
            "SNWD               -1.8308      4.642     -0.394      0.693     -10.941       7.279\n",
            "TMAX               63.6645      4.785     13.306      0.000      54.275      73.054\n",
            "TMIN              -37.1413      5.413     -6.862      0.000     -47.763     -26.519\n",
            "AWND               -1.8502      0.910     -2.033      0.042      -3.637      -0.064\n",
            "Total_yesterday     0.2934      0.022     13.630      0.000       0.251       0.336\n",
            "Mon               790.2012     41.051     19.249      0.000     709.640     870.763\n",
            "Tue               441.4649     32.982     13.385      0.000     376.739     506.191\n",
            "Wed               376.8835     33.935     11.106      0.000     310.287     443.480\n",
            "Thu               282.8744     33.665      8.403      0.000     216.808     348.941\n",
            "Fri                52.4558     32.802      1.599      0.110     -11.918     116.829\n",
            "Sat             -1103.8595     32.242    -34.237      0.000   -1167.133   -1040.586\n",
            "Sun              -806.9722     40.114    -20.117      0.000    -885.695    -728.250\n",
            "holiday          -983.4044     78.191    -12.577      0.000   -1136.853    -829.955\n",
            "daylight_hrs       70.3750      8.400      8.378      0.000      53.890      86.860\n",
            "Temp (C)           13.2616      1.252     10.591      0.000      10.804      15.719\n",
            "dry day           301.0276     33.915      8.876      0.000     234.471     367.584\n",
            "annual             44.6618     16.620      2.687      0.007      12.045      77.279\n",
            "==============================================================================\n",
            "Omnibus:                       35.650   Durbin-Watson:                   1.665\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               78.276\n",
            "Skew:                           0.188   Prob(JB):                     1.01e-17\n",
            "Kurtosis:                       4.345   Cond. No.                     2.64e+19\n",
            "==============================================================================\n",
            "\n",
            "Warnings:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 1.09e-29. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "edpJ87A8A8sd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Feature engineering, explained by Francois Chollet\n",
        "\n",
        "> _Feature engineering_ is the process of using your own knowledge about the data and about the machine learning algorithm at hand to make the algorithm work better by applying hardcoded (nonlearned) transformations to the data before it goes into the model. In many cases, it isn’t reasonable to expect a machine-learning model to be able to learn from completely arbitrary data. The data needs to be presented to the model in a way that will make the model’s job easier.\n",
        "\n",
        "> Let’s look at an intuitive example. Suppose you’re trying to develop a model that can take as input an image of a clock and can output the time of day.\n",
        "\n",
        "> If you choose to use the raw pixels of the image as input data, then you have a difficult machine-learning problem on your hands. You’ll need a convolutional neural network to solve it, and you’ll have to expend quite a bit of computational resources to train the network.\n",
        "\n",
        "> But if you already understand the problem at a high level (you understand how humans read time on a clock face), then you can come up with much better input features for a machine-learning algorithm: for instance, write a Python script to follow the black pixels of the clock hands and output the (x, y) coordinates of the tip of each hand. Then a simple machine-learning algorithm can learn to associate these coordinates with the appropriate time of day.\n",
        "\n",
        "> You can go even further: do a coordinate change, and express the (x, y) coordinates as polar coordinates with regard to the center of the image. Your input will become the angle theta of each clock hand. At this point, your features are making the problem so easy that no machine learning is required; a simple rounding operation and dictionary lookup are enough to recover the approximate time of day.\n",
        "\n",
        "> That’s the essence of feature engineering: making a problem easier by expressing it in a simpler way. It usually requires understanding the problem in depth.\n",
        "\n",
        "> Before convolutional neural networks became successful on the MNIST digit-classification problem, solutions were typically based on hardcoded features such as the number of loops in a digit image, the height of each digit in an image, a histogram of pixel values, and so on.\n",
        "\n",
        "> Neural networks are capable of automatically extracting useful features from raw data. Does this mean you don’t have to worry about feature engineering as long as you’re using deep neural networks? No, for two reasons:\n",
        "\n",
        "> - Good features still allow you to solve problems more elegantly while using fewer resources. For instance, it would be ridiculous to solve the problem of reading a clock face using a convolutional neural network.\n",
        "> - Good features let you solve a problem with far less data. The ability of deep-learning models to learn features on their own relies on having lots of training data available; if you have only a few samples, then the information value in their features becomes critical.\n"
      ]
    },
    {
      "metadata": {
        "id": "oux-dd-5FD6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# ASSIGNMENT\n",
        "\n",
        "### Core assignment\n",
        "\n",
        "Complete the notebook cells that were originally commented **`TODO`**. \n",
        "\n",
        "Then, focus on feature engineering to improve your cross validation scores. Collaborate with your cohort on Slack. You could start with the ideas [Jake VanderPlas suggests:](https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html#Example:-Predicting-Bicycle-Traffic)\n",
        "\n",
        "> Our model is almost certainly missing some relevant information. For example, nonlinear effects (such as effects of precipitation and cold temperature) and nonlinear trends within each variable (such as disinclination to ride at very cold and very hot temperatures) cannot be accounted for in this model. Additionally, we have thrown away some of the finer-grained information (such as the difference between a rainy morning and a rainy afternoon), and we have ignored correlations between days (such as the possible effect of a rainy Tuesday on Wednesday's numbers, or the effect of an unexpected sunny day after a streak of rainy days). These are all potentially interesting effects, and you now have the tools to begin exploring them if you wish!\n",
        "\n",
        "At the end of the day, take the last step in the \"universal workflow of machine learning\" — \"You can train your final production model on all the available data (training and validation) and evaluate it one last time on the test set.\"\n",
        "\n",
        "See the [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) documentation for the `refit` parameter, `best_estimator_` attribute, and `predict` method:\n",
        "\n",
        "> **refit : boolean, or string, default=True**\n",
        "\n",
        "> Refit an estimator using the best found parameters on the whole dataset.\n",
        "\n",
        "> The refitted estimator is made available at the `best_estimator_` attribute and permits using `predict` directly on this `GridSearchCV` instance.\n",
        "\n",
        "### More options\n",
        "\n",
        "**A.** Apply this lesson to other datasets.\n",
        "\n",
        "**B.** We predicted the number of bicycle trips based on that day's weather. But imagine you were asked to predict trips at the beginning of each day, based only on data known at the time of prediction or before — so you cannot use the current day's weather. How would you wrangle the features to handle this new requirement? How does this impact the predictive accuracy and coefficients of your models?\n",
        "\n",
        "**C.** In additon to `GridSearchCV`, scikit-learn has [`RandomizedSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html), which is sometimes even better. Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
        "\n",
        "**D.** _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
        "\n",
        "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
        "\n",
        "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Bk_HJrxPr_CF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qS8eJi-brtIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "outputId": "5d3f507d-5a7b-4714-d855-e4f242a68cfa"
      },
      "cell_type": "code",
      "source": [
        "#https://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import (LinearRegression, Ridge, \n",
        "                                  Lasso)\n",
        "from sklearn.feature_selection import RFE,RFECV,f_regression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# CV returns a dictionary so.... \n",
        "scores2 = cross_validate(RANSACRegressor(LinearRegression(), max_trials=100, min_samples = 50, loss='absolute_loss'), X_train, y_train, scoring='neg_mean_absolute_error', cv = 3, return_train_score=True, return_estimator=True)\n",
        "np.random.seed(0)\n",
        " \n",
        "size = 750\n",
        " \n",
        "Y = y_train\n",
        "X = X_train\n",
        "\n",
        "names = list(X.columns)\n",
        "\n",
        "# Rank the outputs from 0 to 1\n",
        "ranks = {}\n",
        "def rank_to_dict(ranks, names, order=1):\n",
        "    minmax = MinMaxScaler()\n",
        "    ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n",
        "    ranks = map(lambda x: round(x, 2), ranks)\n",
        "    return dict(zip(names, ranks ))\n",
        "\n",
        "#### Regression Types #### \n",
        "# Linear Regression\n",
        "lr = LinearRegression()\n",
        "lr.fit(X, Y)\n",
        "ranks[\"Linear Regression\"] = rank_to_dict(np.abs(lr.coef_), names)\n",
        "\n",
        "# Random Forest Regression\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(X,Y)\n",
        "ranks[\"Random Forest\"] = rank_to_dict(rf.feature_importances_, names)\n",
        "\n",
        "# F Regression\n",
        "f, pval  = f_regression(X, Y, center=True)\n",
        "ranks[\"Corr. (p_value)\"] = rank_to_dict(f, names)\n",
        "\n",
        "# Ridge Regression\n",
        "ridge = Ridge(normalize=True, alpha=7)\n",
        "ridge.fit(X, Y)\n",
        "ranks[\"Ridge Regression\"] = rank_to_dict(np.abs(ridge.coef_), names)\n",
        "\n",
        "# Lasso Regression\n",
        "lasso = Lasso(normalize=True, alpha=.05)\n",
        "lasso.fit(X, Y)\n",
        "ranks[\"LASSO\"] = rank_to_dict(np.abs(lasso.coef_), names)\n",
        "\n",
        "#Linear Regression RFE - stop the search when 5 features are left (they will get equal scores)\n",
        "rfe = RFE(LinearRegression(normalize=True), n_features_to_select=1)\n",
        "rfe.fit(X,Y)\n",
        "ranks[\"Recursive Feature Elimination\"] = rank_to_dict(([float(i) for i in rfe.ranking_]), names, order=-1)\n",
        "\n",
        "\n",
        "### MEAN OF REGRESSION COEFFICIENTS\n",
        "r = {}\n",
        "for name in names: r[name] = round(np.mean([ranks[method][name]for method in ranks.keys()]), 2)\n",
        "ranks[\"Feat.Select Mean\"] = r\n",
        "\n",
        "methods = list(ranks.keys())\n",
        "\n",
        "df_tabs = pd.DataFrame.from_dict(ranks)\n",
        "df_tabs = df_tabs[methods]\n",
        "df_tabs#.sort_values(by='MSE')\n",
        "\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Linear Regression</th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Corr. (p_value)</th>\n",
              "      <th>Ridge Regression</th>\n",
              "      <th>LASSO</th>\n",
              "      <th>Recursive Feature Elimination</th>\n",
              "      <th>Feat.Select Mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>AWND</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fri</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mon</th>\n",
              "      <td>0.71</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PRCP</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SNOW</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SNWD</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sat</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.90</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sun</th>\n",
              "      <td>0.73</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.78</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TMAX</th>\n",
              "      <td>0.06</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TMIN</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Temp (C)</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Thu</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total_yesterday</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tue</th>\n",
              "      <td>0.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Wed</th>\n",
              "      <td>0.34</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>annual</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>daylight_hrs</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dry day</th>\n",
              "      <td>0.27</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>holiday</th>\n",
              "      <td>0.89</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.46</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Linear Regression  Random Forest  Corr. (p_value)  \\\n",
              "AWND                          0.00           0.02             0.05   \n",
              "Fri                           0.04           0.01             0.00   \n",
              "Mon                           0.71           0.09             0.02   \n",
              "PRCP                          0.51           0.16             0.16   \n",
              "SNOW                          0.00           0.00             0.00   \n",
              "SNWD                          0.00           0.00             0.00   \n",
              "Sat                           1.00           0.32             0.15   \n",
              "Sun                           0.73           0.16             0.16   \n",
              "TMAX                          0.06           1.00             0.89   \n",
              "TMIN                          0.03           0.02             0.37   \n",
              "Temp (C)                      0.01           0.02             0.69   \n",
              "Thu                           0.25           0.00             0.02   \n",
              "Total_yesterday               0.00           0.44             1.00   \n",
              "Tue                           0.39           0.00             0.04   \n",
              "Wed                           0.34           0.00             0.04   \n",
              "annual                        0.04           0.03             0.02   \n",
              "daylight_hrs                  0.06           0.10             0.70   \n",
              "dry day                       0.27           0.01             0.23   \n",
              "holiday                       0.89           0.02             0.01   \n",
              "\n",
              "                 Ridge Regression  LASSO  Recursive Feature Elimination  \\\n",
              "AWND                         0.01   0.00                           0.17   \n",
              "Fri                          0.12   0.16                           0.89   \n",
              "Mon                          0.44   0.37                           0.78   \n",
              "PRCP                         1.00   0.41                           0.39   \n",
              "SNOW                         0.00   0.00                           0.00   \n",
              "SNWD                         0.02   0.00                           0.11   \n",
              "Sat                          0.90   1.00                           0.94   \n",
              "Sun                          0.87   0.78                           1.00   \n",
              "TMAX                         0.06   0.05                           0.56   \n",
              "TMIN                         0.06   0.02                           0.50   \n",
              "Temp (C)                     0.07   0.00                           0.44   \n",
              "Thu                          0.32   0.00                           0.83   \n",
              "Total_yesterday              0.00   0.00                           0.06   \n",
              "Tue                          0.47   0.11                           0.67   \n",
              "Wed                          0.43   0.07                           0.72   \n",
              "annual                       0.13   0.03                           0.22   \n",
              "daylight_hrs                 0.16   0.05                           0.28   \n",
              "dry day                      0.61   0.22                           0.33   \n",
              "holiday                      0.56   0.70                           0.61   \n",
              "\n",
              "                 Feat.Select Mean  \n",
              "AWND                         0.04  \n",
              "Fri                          0.20  \n",
              "Mon                          0.40  \n",
              "PRCP                         0.44  \n",
              "SNOW                         0.00  \n",
              "SNWD                         0.02  \n",
              "Sat                          0.72  \n",
              "Sun                          0.62  \n",
              "TMAX                         0.44  \n",
              "TMIN                         0.17  \n",
              "Temp (C)                     0.20  \n",
              "Thu                          0.24  \n",
              "Total_yesterday              0.25  \n",
              "Tue                          0.28  \n",
              "Wed                          0.27  \n",
              "annual                       0.08  \n",
              "daylight_hrs                 0.22  \n",
              "dry day                      0.28  \n",
              "holiday                      0.46  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "iVF-nABrsQov",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "J"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}